{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWE Forecasting with Machine Learing (ML)\n",
    "In this lab we will develop a machine learning model to predict snow water equivalent in the mountains. This labs takes datasets we have looked at in various ways in  prior labs and integrates thouse findings in to a machine learning model that can preict SWE in the mountains of Afganistan. \n",
    "\n",
    "#### Machine learning modls are statistical methods that take ***predictors*** as inputs and generate a ***target*** output. \n",
    "\n",
    "The ML model we are going to predict SWE with is called **Random Forest**. We will be developeing a model that predicts SWE for ~10km2 areas of the Panjashir Basin in Afganistan. In our model, we are going to use a mix of static charateristics about each location, like elevation, and dynamic charatieristics like snow covered area. All of the predictors are avalible in near real time during the snow season. To train and validate our model, since we do not have spatially distributed in situ mesurements of SWE, we will be using reconstucted SWE, the SWE produt we explored in Lab 3, which is the clsest ground truth avalible for data-sparse regions with minimal cloud cover durring the melt season. \n",
    "\n",
    "\n",
    "## Lab Outline\n",
    "- Learn how to train, run, and anlyize a Random Forest machine learning model with a pratice dataset.\n",
    "- Understand the set up of a Machine Learning model for SWE prediciton.\n",
    "- Train a SWE machine learning model\n",
    "- Run a SWE machine learning model\n",
    "- Vizualize machine learning model output\n",
    "- Use the SWE machine learning model to make SWE predictions for various water years\n",
    "- Compare the SWE machine learning model predictions to alternative methods from Lab 1 and Lab 3\n",
    "\n",
    "This lab uses the methods developed and published here: https://doi.org/10.5194/tc-12-1579-2018\n",
    "\n",
    "\n",
    "# Part 1: Picking the right model. \n",
    "\n",
    "## Machine Learning Overview - Classification vs Regression\n",
    "In general there are two main types of machine learning models. They are differenitead based on the type of output they produce. \n",
    "- ***Classificaiton*** models catagorize outputs. Classificaiton models predict a catagorical class based on the predictor data. \n",
    "- ***Regression*** models return continous output. Regression models predict an answer along a continous range of values. \n",
    "\n",
    "Many apporaches to machine learning, can be tweaked to model data in either of these two ways. The first important step in setting up an ML model is to ask yoursuelf: \n",
    "#### ***What is the output I want from my model? Is it catagorical or continous?***\n",
    "\n",
    "\n",
    "## GROUP QUESTIONS: \n",
    "### ***For our SWE ML model what is our output variable, the \"target\" of the model?***\n",
    "\n",
    "### ***What type of ML model do we want, a Classificaiton or a Regression model?***\n",
    "\n",
    "Snow water equivalent is our target variable. SWE is a continous variable. We want to use a regression model. SWE values can range continously from zero millimeters to upwards of  hundreds of millimeters.  This is the most importnat point when looking into finding a solution that can predict SWE - knowning that we are interested in a regression model that outputs a continous variable lets us focus in on this specific type of machine learning model to find a solution. \n",
    "\n",
    "\n",
    "## Random Forest Models\n",
    "\n",
    "Random forst models can be set up to perfrom classificaiton or regression. We will be using the scikit-learn in python to implement a regression random forest ML algorithm to predict SWE. Below are references to documentaion on the scikit-learn emplementaiton we will use:\n",
    "- scikit-learn overview: https://scikit-learn.org/stable/index.html\n",
    "- random forest implementation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "- scikit-learn \"make regression\" function, great for learning how algorithms work: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html \n",
    "\n",
    "\n",
    "Random forest models are based on decision trees. https://en.wikipedia.org/wiki/Decision_tree\n",
    "\n",
    "Instead of making one decison tree for our prediciton, a Random Forest algorithm make many decision trees that are all slightly different. With an esmeble of trees, our prediction is the average of all preditions across the trees that we have trained with our training set. \n",
    "\n",
    "***the main insight behind Random Forests performing better than any single decion tree is that the average answer of all the deision trees is going to be a better prediction than predictions from any single decision tree.***\n",
    "\n",
    "\n",
    "## Growing the Random Forest: Bagging and Bootstrapping\n",
    "\n",
    "How do we create these replicated trees? How do we make sure that they are different yet represenative of our dataset so that we can leverage results of all the trees into one prediciton?\n",
    "\n",
    "We use a technique called ***Bagging***\n",
    "Bagging is a technique where we create a large number of trees by taking \"bootstapped\" samples from our dataset. \n",
    "a ***Bootstrapped*** sample is sampling with replacement. Each randomized subset of data that we extract is picked from the full dataset. ***This means that individual measurements can be in multiple trees, but no two trees will be the same.***\n",
    "\n",
    "Becuase each tree will be unique, they will all produce slightly different answers. think of each indivual decision tree that we created by taking a bagged sample from the main dataset as its own stand alone descions tree. What we are going to do is use the main assumption of this method which is that ***The averaged output of all the ensemble trees is a better answer than any one individual trees prediciton***. But at the core of the algorihtm, each bagged tree is a simple decision tree in the middle of a large **\"Random Forest\"**. We created a ***\"forest\"*** of decison trees with a randomzed method. \n",
    "\n",
    "The last detail about the random forest, is that in addition to randomly selecting datapoints to be used to create each tree, each split in the tree is generated with a random subset of predictors. So ***each tree is grown from a different subset of predictiors and trained on a differnet subset of data from our dataset.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Creating a Random Forest algorithm on example data\n",
    "Before we use SWE data, lets explore how the algorthm works, and ways to evalute performance with a smaller and simpler implementation. We can use the make_regression function in scikit-learn to generate a dataset of predictors and outcomes that have a known relationship, with some noise thrown in. This lets us explore how the model works, how we can understand how well it performs, and things we can modify to try an increase preformance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Lab workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything we need for the lab\n",
    "import sklearn\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import log as ln\n",
    "from joblib import load\n",
    "import geopandas as gpd \n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an example dataset to practice with\n",
    "The funciton below is a easy way to quickly create an example dataset. Data that is in the correct format and ready to use to try running machine learning models. The **make_regression** function creates a dataset **\"X\"** which predicts **\"Y\"**. \n",
    "we have set it up to generate a dataset with 2000 samples with 15 features and 7 of the features are useful for predicting Y. \n",
    "- This is important. Commong to many machine learning problems is that sometimes featueres you have chosen are not that great at generateing predicitons. You want to know if you can identify which predictors are poor, or if the model still preforms well even if some of the input data is of low quality.\n",
    "\n",
    "Y is a scalar output i.e. one continous value, we have added some noise to the dataset and set \"random_state\" which means that each time we call this funciton, the results are reproducable. To see why this matters, try running\n",
    "this section of code with the example test data without the random_state paraemter set, and see what happend to your answers each time the code is run! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets generate a test case to learn about how the random forest machine learning algorihtm works\n",
    "#X = the set of predictors, variables that we use to predit our outcome\n",
    "#Y = the outcome, the value we want to predict with our model. \n",
    "\n",
    "\n",
    "# create the dataset\n",
    "X,Y=make_regression(n_samples=2001,n_features=15,n_informative=7,n_targets=1,noise=0.15,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictor similarity with correlation plot \n",
    "A good way to look at how useful predictor variables might be is to use a correlation plot. \n",
    "\n",
    "Correlation between predictors and targets is desirable\n",
    "but correlation between predictors, called collinearity, is not.\n",
    "Collinearity does not degrade the performance of the models,\n",
    "but makes assessment of the importance of the correlated predictors\n",
    "independently more difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(X)\n",
    "correlations = data.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,15,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Random Forest model\n",
    "The scikit-learn function **RandomForestRegressor** is how we generate a random forest regressor model. Since our dataset we made has 2000 datapoints, we can use the first 1999 datapoints to train the model and then see how well it does predicting the 2000th datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to train a random forest regressor to predict Y from X\n",
    "model=RandomForestRegressor()\n",
    "\n",
    "#fit the model with the first 2000 datapoint in our dataset\n",
    "trainX=X[0:1999,:]\n",
    "trainY=Y[0:1999]\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction with the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the outcome Y on the last datapoint\n",
    "testX=X[2000,:]\n",
    "testX=testX.reshape(1,-1)\n",
    "\n",
    "#lets keep track of the value we are trying to predict with the model, we can compare this \"truth\" value\n",
    "#to the model output.\n",
    "truthY=Y[2000]\n",
    "\n",
    "#lets run the trained ML model and try and predict Y\n",
    "predictY=model.predict(testX)\n",
    "print('Prediction: ' + str(predictY[0]) + ' Truth: ' + str(truthY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictor feature importance\n",
    "one nice aspect of random forest models is that we can visualize how important each feature was at making the final predictions. This is a good way to help understand which of your predictors are most helpful at arriving at useful predicitons. You can use this information to try various preditors and priotitize which datasets you want ot be usre to include in future models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and plot feature importance\n",
    "sorted_idx = model.feature_importances_.argsort()\n",
    "\n",
    "#define plot space\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "#plot each features importance as a bar chart\n",
    "plt.barh(data.columns.values[sorted_idx], model.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.ylabel(\"Feature Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have used a random forest algorithm and explored how it can be used to predict outcomes and evaluate its performance, lets now use these methods to predict the snow water equivalent in the panjasher basin in afganistan. \n",
    "\n",
    "# PART 2: SWE ML in Panjasher Basin of Afganistan\n",
    "\n",
    "## Predictors and Targets\n",
    "A mix of static physiographic and dynamic variables are used. \n",
    "The time period each year the model is run is april-june and the years are 2003-2011\n",
    "The spatial resolution of the model is 3.125x3.125km.\n",
    "All of the variables below have been assembled into tables that are ready to be input into our Random Forest ML models. \n",
    "\n",
    "### Physiographic Predictors:\n",
    "| Name | Description|\n",
    "|-------|------|\n",
    "| Day of Year | we use the sine of the day of year, this enables us to model day of year as a continous variable |\n",
    "| Elevation | Pixel average elevation |\n",
    "| Latitude | Pixel center latitude |\n",
    "| Longitude | Pixel center longitude |\n",
    "| Northwest/west/southwest barrier difference \"shield height\" | Elevation difference between pixel and highest pixel in each direction |\n",
    "| West/southwest distance to ocean | Pixel distance to ocean or sea in each direction |\n",
    "| Southness | Computed as sin(slope) X cos(aspect), with slope as upward from horizontal and spects from south with counter-clockwise as positive |\n",
    "\n",
    "### Dynamic Predictors:\n",
    "| Name | Description|\n",
    "|-------|------|\n",
    "|TB<sub>10V</sub>-TB<sub>18V</sub>| Difference between ehnahced resolution PM brightnes temperature at 10GHz, vertically polarized, and 18 GHz, vertically polarized |\n",
    "|TB<sub>18V</sub>-TB<sub>36V</sub>| Difference between ehnahced resolution PM brightnes temperature at 18GHz, vertically polarized, and 36 GHz, vertically polarized |\n",
    "| F<sub>sca</sub> | Fractional snow-coverewd area |\n",
    "| Mean reconstructed SWE | Mean daily SWE computted over all years except the target year |\n",
    "\n",
    "### Target:\n",
    "| Name | Description|\n",
    "|-------|------|\n",
    "| Reconstructed SWE | Reconstructed daily SWE |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Passive Microwave info:***\n",
    "Only nighttime data from the microwave brightness temperatures is used. The snowpack is usually frozen at night and passive microwave data cannot retieve SWE from wet snow. The 36 GHzV (vertical polarization) brightness temperatures are available at 3.125 km, but the 18 GHzV brightness temperatures are available only at a resolution of 6.25 km, so the 18 GHz brightness temperatures were resampled to the 3.125 km resolution. Likewise, the 10 GHz brightness temperatures are available only at 12.5 km resolution, so they were also resampled to 3.125 km. Two different brightness temperature differences (T<sub>18V</sub>–T<sub>36V</sub> and T<sub>10V</sub>–T<sub>18V</sub>) are used to account for shallow and deep snow.\n",
    "\n",
    "As we learned in Lab 1, the passive mirowave data is not collected each day - there are gaps between swaths of satellite data at the latitude of afganistan. We fill these gaps by using bilinear interpolation and then smoothed using a 7-day moving median filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a year to predict SWE for:\n",
    "We will start by trying to predict the daily SWE in the Panjasher basin durring the melt season of 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testYear=2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "\n",
    "For  model training, we will try and predict SWE from each year of our dataset by using the other years of data as training data. First, we will try and predict 2011 SWE by selecting 80,000 training observations from 2003-2010 to train the model on. Then, with the trained model, we will use the predictors from 2011 to try and predict the target year SWE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a sample of 80,000 observations to train the model on. \n",
    "# We want these observations to be sampled from all of our data we have from 2003-2010\n",
    "\n",
    "file_name = '{}Table.csv'\n",
    "# create the table of samples sfrom 2003-2010\n",
    "# fyi - range function does not include the stop number (2011)\n",
    "k=1\n",
    "for i in range(2003, 2012):\n",
    "    \n",
    "    #dont sample from the year we are predicting\n",
    "    if i==testYear:\n",
    "        continue\n",
    "        \n",
    "    print(i)\n",
    "    #read in the years data\n",
    "    tmpTbl=pd.read_csv(file_name.format(i))\n",
    "    \n",
    "    # delete pixels without fsca and outside of the basin\n",
    "    tmpTbl = tmpTbl[(tmpTbl.fsca != 0) & (tmpTbl.mask != 0)]\n",
    "\n",
    "    # sample 10,000 observations from this year\n",
    "    tmpTbl=tmpTbl.sample(n=10000,random_state=1)\n",
    "    \n",
    "    #create a new training table of the sampled values from each year\n",
    "    if k==1:\n",
    "        trainTbl=tmpTbl\n",
    "    else:       \n",
    "        trainTbl=pd.concat([trainTbl, tmpTbl])\n",
    "    k=k+1\n",
    "\n",
    "trainTbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that we created a table with 80,000 rows of observations and 18 features. Lets look at the data in the table, these are a mix of features for each pixel that might help us predict the SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTbl.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create target variable \n",
    "Our measure of SWE, that we are using at the truth for our model training is reconstucted SWE. we will pull that variable out of our table and set it as **Y** our **Target Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=trainTbl.recon_swe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our predictor features DataFrame\n",
    "Now that we have seen the data, we need to clean it up a bit. First, we do not want our output in the predictor table anymore. We need to remove reconstructed SWE from the table. We also do not want to predict SWE for pixels with 0 fsca, as we already know the answer (0 SWE). The model would be able to easily predict the output for these rows, and give us a false since of accuracy of our model. We only want to train and test the model on rows where we have fractional snow cover. Afganisatn does not have much canopy cover - most of the pixels with canopy cover range from 1-2% vegitative cover, so we will remove this varibale as well. We also have a dupliate of DOY (day of year) and doy_sin. doy_sin is a continous variable for doy that we want to use instead of the actual date, so we will delete to doy variable. The mask variable is 1 for all pixel that are wihtin the basin. Since every row of our predictor table is within the basin, we can delete this varibale and not use it for predictions. Generally, if you have a feature that is exactly the same for evey observation, it will not be useful to include in a ML model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# just delete the traget variable, we want to use all the predicitos\n",
    "###trainTbl=trainTbl.drop(columns=['recon_swe','doy','cc','mask']) \n",
    "###trainTbl.head(50)\n",
    "\n",
    "#TEST - JUST USE THE FEATURES THAT ARE PREDICTIVE\n",
    "trainTbl = trainTbl[['doy_sin', 'Elevation_m', 'fsca','TB10V_TB18V','TB18V_TB36V','recon_swemean']].copy()\n",
    "trainTbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainTbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above we can see that we now have a table with 80,0000 observations at 6 features for each observation. This is the final set of data we want to use to train our model. \n",
    "\n",
    "A good thing to always check it to make sure that all the input data is valid. Sometimes models can handle missing values, sometimes they cannot. The random forest algo cannot handel missing values, so we need ot check and make sure that no rows have any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainTbl.dropna() \n",
    "trainTbl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code to drop any rows that have missing data for any features we can see that our dataset did not change size, we still have 80,000 rows. This is good. This means that all of our 80,000 observations have data for each of the 6 features that we will use to predict SWE.\n",
    "\n",
    "## Visualize Predictors with correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = trainTbl.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,6,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(trainTbl.columns.values,rotation = 90)\n",
    "ax.set_yticklabels(trainTbl.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the SWE ML model\n",
    "\n",
    "ADD TEXT HERE. Training can take some time. Be patient..... It can take 10-15 minutes.  \n",
    "\n",
    "Take this time to go back to the top part of the lab and think about what is going on in the model training.....\n",
    "\n",
    "The model is using all 80,0000 observations and 6 features to randomly select subsets of the 80,000 observations and randomly select subsets of the 6 features to create many decisions trees and train each decision tree on the subset of the data is was grown with. It is then putting all the trees togeather into one model that can pass input data into all the trees and average all the tress outputs into one answer that will be returend to use from the trained model. \n",
    "\n",
    "\n",
    "ADD SAVED TRAINED MODELS FOR EACH COMBINCATION OF YEARS....\n",
    "\n",
    "\n",
    "Generally you want a large number of \"trees\" in your \"random forest\" each tree that is added to the forest increases the size of the saved ML model. The default in scikit-learn is to build a model with 100 trees. For our dataset, that creates  models that are ~500MB uncompressed and ~100MB compressed. Inreasing the number of trees can improve the model and decreasing the number of trees can improve the seppd of the model and make it more portable. To experiment in this lab, we will be using small random forests of 10 trees each to reduce the size of our image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in format for bagged algo\n",
    "#we want to train a random forest regressor to predict Y from X\n",
    "SWEmodel=RandomForestRegressor(n_estimators=5) #default it 100 (too large for Binder Image)\n",
    "\n",
    "#train the model on the dataset\n",
    "SWEmodel.fit(trainTbl, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in test year data to predict SWE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  we will try and predict the SWE for this year based on out model trained with data from the other years.\n",
    "sweTbl=pd.read_csv(str(testYear)+\"Table.csv\")\n",
    "# delete pixels without fsca and outside of the basin\n",
    "sweTbl = sweTbl[(sweTbl.fsca != 0) & (sweTbl.mask != 0)]\n",
    "\n",
    "#testing data to validaitate the model\n",
    "truthSWE=sweTbl.recon_swe\n",
    "\n",
    "#location of each location we train the model for mapping later\n",
    "lat=sweTbl['Latitude']/100\n",
    "lon=sweTbl['Longitude']/100\n",
    "\n",
    "#predictors of SWE that go into the model - same as 2003-2010 data\n",
    "doy=sweTbl.doy # we need this later\n",
    "###sweTbl=sweTbl.drop(columns=['recon_swe','doy','cc','mask']) \n",
    "sweTbl = sweTbl[['doy_sin', 'Elevation_m', 'fsca','TB10V_TB18V','TB18V_TB36V','recon_swemean']].copy()\n",
    "sweTbl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Random Forest Model to make SWE predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets run the trained ML model and try and predict SWE\n",
    "predictSWE=SWEmodel.predict(sweTbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize SWE predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lets vizualize our SWE prediction,\n",
    "# first lets take our output and the lat/lon locations and\n",
    "#turn into a dataframe for easy plotting\n",
    "SWE=pd.DataFrame(data={'doy':doy,'lat':lat,'lon':lon,'SWE':predictSWE})\n",
    "plotSWE=SWE[SWE.doy==130]\n",
    "plotSWE.plot(kind=\"scatter\", x=\"lon\", y=\"lat\",\n",
    "                      c=plotSWE['SWE'],cmap=plt.get_cmap('jet'),\n",
    "                      colorbar=True, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graphic is Okay, but we want to see the SWE estimates in the local context. the output above has not geogrpahic information associated with the plot - we jsut used longitude and latitude as X and Y coordiantes. NExt, we will add geographic infomraiton to our datframe and then flow th answers over a basemap. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SWE predicitons on a Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shapefile boundary of our AOI\n",
    "aoiFile='panjsher_basin_afghanistan_wgs84.shp'\n",
    "#load\n",
    "AOI = gpd.read_file(aoiFile)\n",
    "AOI.crs= \"EPSG:4326\"\n",
    "\n",
    "#convert the dataframe with our marchine learing output into a geodataframe\n",
    "geometry = [Point(xy) for xy in zip(plotSWE.lon, plotSWE.lat)]\n",
    "geoSWE = plotSWE.drop(['lon', 'lat'], axis=1)\n",
    "geoSWE = gpd.GeoDataFrame(geoSWE, crs=\"EPSG:4326\", geometry=geometry)\n",
    "\n",
    "#plot\n",
    "fig,ax=plt.subplots(figsize=(15,15))\n",
    "\n",
    "#basin boundary in purple\n",
    "ax = AOI.plot(ax=ax, edgecolor=\"purple\", facecolor=\"None\", zorder=1)\n",
    "\n",
    "#SWE data with colorbar\n",
    "ax = geoSWE.plot(ax=ax, column='SWE', markersize=100, cmap='jet', legend=True, zorder=2)\n",
    "\n",
    "#basemap\n",
    "ctx.add_basemap(ax, crs=\"EPSG:4326\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate basin wide SWE depletion prediction curve\n",
    "\n",
    "These data as in Labs 1 and 3 are in an equal area projection, so it is easy to see the basin wide SWE each day. Lets calculate the estimate of the total SWE in the basin on a single day. TO do this we need to get the area of the basin, we can then use this equaiton to estiamte the total columne of water stored as seasonal snow in the basin. The panjashir basin is 4373 square kilomters. Our pixel size for the Machine Learning model is 3.125x3.125km pixels, so each pixel is 9.7656 square kilometers.\n",
    "\n",
    "pixelsize (km2) * depth of SWE (km) =sum for all pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate volume in each pixel\n",
    "#convert mm to km and then multiply depth (in km) by area (in km2) to get vol (km3)\n",
    "SWE['pxlVol']=SWE['SWE']*1e-6*3.125*3.125\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize basin wide SWE depletion prediction curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have a column that is the volume in cubic kilometers of each pixel, we can sum by day to see\n",
    "#our estimate of the daily water sotrage in the basin.\n",
    "\n",
    "#define plot space\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "#define x and y axis data\n",
    "SWE.groupby('doy')['pxlVol'].sum().plot(kind='line',x='day of year',y='SWE (mm)',color='orange', ax=ax)\n",
    "\n",
    "#set plot title and axes labels\n",
    "ax.set(title=str(testYear)+' SWE prediciton each day',\n",
    "       xlabel='day of year',\n",
    "       ylabel='SWE (Km3)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Compare ML SWE Predictions to other methods\n",
    "\n",
    "In the other labs we have explored other ways to estimate SWE in the Panjasher Basin. Lets now compare each method to each other method and see how the SWE ML answers compare. \n",
    "\n",
    "First, one way we can visually look at how our machine learning estimate does each day is to compare it to the reconstructed SWE estimate that we have for the basin - the variable we trained the model to predit. Since we are using historical data in the lab, we have the reconstruction data avalible for any year we choose to try and predict the SWE. We can plot reconstructed SWE alongside the machine learning prediciton to compare the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SWE['truthSWEpxlVol']=truthSWE*1e-6*3.125*3.125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ML SWE and Reconstructed SWE\n",
    "\n",
    "In the table above you can see that we have two columns now, 'pxlVol' is the machine learning predition for the volume of water in the 3.125km by 3.125km pixel and then 'truthSWEpxlVol' is our 'truth' measurement, the reconstructed SWE that we can calculate after the fact using the energy balance method from Lab 2.  As a first comparison, lets plot against each other for the whole basin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define plot space\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "#define x and y axis data - Machine Learning Prediction\n",
    "SWE.groupby('doy')['pxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='orange', label= 'Machine Learning Prediciton', ax=ax)\n",
    "\n",
    "#define x and y axis data - Truth data from SWE reconstruciton\n",
    "SWE.groupby('doy')['truthSWEpxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='purple', label = 'SWE reconstruction', ax=ax)\n",
    "\n",
    "#set plot title and axes labels\n",
    "ax.set(title=str(testYear)+' SWE prediciton each day',\n",
    "       xlabel='day of year',\n",
    "       ylabel='SWE (Km3)')\n",
    "\n",
    "#plot all the data\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the machine learning prediction is just okay. lets dive in now and see how our different predictors helped us predict SWE and see if we can gain any insight into why our predciton is off. \n",
    "\n",
    "## Plot ML SWE, Reconstruction SWE, AMSR SWE, and ERA-5 SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load the PM and AMSRSWE basin predicitons and plot as well. - Need to have these data cleaned and imported. \n",
    "file_name = '{}BasinSWE_km3_AMSR_ERA5.csv'\n",
    "opSWE=pd.read_csv(file_name.format(testYear))\n",
    "opSWE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the operational SWE products for this basin. Why are there -99 values on some days for the AMSR swe product? \n",
    "hint ( think about lab 1 and what we learned about passive microwave measurements) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-99 are fill values for days we dont have passive microwave measurements.\n",
    "opSWE.loc[opSWE['basinSWE_amsr']==-99,'basinSWE_amsr']=np.nan\n",
    "opSWE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets plot the reconstructed swe, the ERA 5 swe estimate, the AMSR SWE estimate for the basin and the Machine learning SWE estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define plot space\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "\n",
    "\n",
    "#define x and y axis data - ERA 5 SWE forecast\n",
    "opSWE.plot.scatter( x='doy',y='basinSWE_amsr',\n",
    "                                        color='green', label= 'AMSR SWE Estimate', ax=ax)\n",
    "\n",
    "#define x and y axis data - AMSR-Unified SWE estimate\n",
    "opSWE.plot(kind='line',x='doy',y='basinSWE_era5',color='black', label= 'ERA 5 SWE forecast', ax=ax)\n",
    "\n",
    "\n",
    "#define x and y axis data - Machine Learning Prediction\n",
    "SWE.groupby('doy')['pxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='orange', label= 'Machine Learning Prediciton', ax=ax)\n",
    "\n",
    "#define x and y axis data - Truth data from SWE reconstruciton\n",
    "SWE.groupby('doy')['truthSWEpxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='purple', label = 'SWE reconstruction', ax=ax)\n",
    "\n",
    "#set plot title and axes labels\n",
    "ax.set(title=str(testYear)+' SWE prediciton each day',\n",
    "       xlabel='day of year',\n",
    "       ylabel='SWE (Km3)')\n",
    "\n",
    "#plot all the data\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill gaps in AMSR SWE estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remake the graph with a cubic spline interpolation of the point estimates from AMSR adn then use a rolling average\n",
    "\n",
    "#calculate the cubic spline estimate of the AMSR data (same as lab 1)\n",
    "amsrSWE_interp=pd.DataFrame(data={'doy':opSWE['doy'],'basinSWE_amsr': opSWE['basinSWE_amsr'].interpolate(method='cubicspline')})\n",
    "\n",
    "# 7 day  moving average of the interpolated data\n",
    "amsrSWE_avg=amsrSWE_interp.rolling(7).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot smoothed estimates of SWE from all methods in the labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define plot space\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "\n",
    "#define x and y axis data - ERA 5 SWE forecast - POINTS\n",
    "#opSWE.plot.scatter( x='doy',y='basinSWE_amsr',\n",
    "#                                        color='green', label= 'AMSR SWE Estimate', ax=ax)\n",
    "\n",
    "#define x and y axis data - ERA 5 SWE forecast - INTERPOLATION\n",
    "#amsrSWE_interp.plot(kind='line', x='doy',y='basinSWE_amsr',\n",
    "#                                        color='green', label= 'AMSR SWE Estimate', ax=ax)\n",
    "\n",
    "\n",
    "#define x and y axis data - ERA 5 SWE forecast - rolling average\n",
    "amsrSWE_avg.plot(kind='line', x='doy',y='basinSWE_amsr', style='--',\n",
    "                                        color='green', label= 'AMSR SWE Estimate', ax=ax)\n",
    "\n",
    "\n",
    "#define x and y axis data - AMSR-Unified SWE estimate\n",
    "opSWE.plot(kind='line',x='doy',y='basinSWE_era5',color='black', label= 'ERA 5 SWE forecast', ax=ax)\n",
    "\n",
    "\n",
    "#define x and y axis data - Machine Learning Prediction\n",
    "SWE.groupby('doy')['pxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='orange', label= 'Machine Learning Prediciton', ax=ax)\n",
    "\n",
    "#define x and y axis data - Truth data from SWE reconstruciton\n",
    "SWE.groupby('doy')['truthSWEpxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='purple', label = 'SWE reconstruction', ax=ax)\n",
    "\n",
    "#set plot title and axes labels\n",
    "ax.set(title=str(testYear)+' SWE prediciton each day',\n",
    "       xlabel='day of year',\n",
    "       ylabel='SWE (Km3)')\n",
    "\n",
    "#plot all the data\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize feature importance from the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate and plot feature importance\n",
    "sorted_idx = SWEmodel.feature_importances_.argsort()\n",
    "plt.barh(trainTbl.columns.values[sorted_idx], SWEmodel.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4: Try yourself - Train a model to predict SWE for another year\n",
    "\n",
    "Now that we have predicted the data for 2011, lets say we wanted to see how the model would work for another year, how could we use our exiting data to train and test for another year besides the lteset year in the dataset (2011)?\n",
    "reuse the code above to train and predict swe for any year from 2003 to 2010. Pick a partner and choose different years to train you model on then compare the output results to each others. We can then at the end go through and everyone can discuss how their model turend out for the year they trained it on. \n",
    "## Pick a new year to model and load the trained random forest model for that year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load a model for a new year\n",
    "newTestYear=2005\n",
    "filename = str(newTestYear)+ '_RFmodel.joblib'\n",
    "\n",
    "# load, no need to initialize the loaded_rf\n",
    "SWEmodel = load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Random Forest model and grab SWE estimates from other methods for the same year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load year of data to predict swe for\n",
    "sweTbl=pd.read_csv(str(newTestYear)+\"Table.csv\")\n",
    "# delete pixels without fsca and outside of the basin\n",
    "sweTbl = sweTbl[(sweTbl.fsca != 0) & (sweTbl.mask != 0)]\n",
    "lat=sweTbl['Latitude']/100\n",
    "lon=sweTbl['Longitude']/100\n",
    "\n",
    "#testing data to validaitate the model\n",
    "truthSWE=sweTbl.recon_swe\n",
    "\n",
    "#predictors of SWE that go into the model - same as 2003-2010 data\n",
    "doy=sweTbl.doy # we need this later\n",
    "sweTbl = sweTbl[['doy_sin', 'Elevation_m', 'fsca','TB10V_TB18V','TB18V_TB36V','recon_swemean']].copy()\n",
    "#lets run the trained ML model and try and predict SWE\n",
    "predictSWE=SWEmodel.predict(sweTbl)\n",
    "SWE=pd.DataFrame(data={'doy':doy,'lat':lat,'lon':lon,'SWE':predictSWE})\n",
    "#swe volumne per pixel\n",
    "SWE['pxlVol']=SWE['SWE']*1e-6*3.125*3.125\n",
    "SWE['truthSWEpxlVol']=truthSWE*1e-6*3.125*3.125\n",
    "\n",
    "#load the PM and AMSRSWE basin predicitons and plot as well.\n",
    "file_name = '{}BasinSWE_km3_AMSR_ERA5.csv'\n",
    "opSWE=pd.read_csv(file_name.format(newTestYear))\n",
    "opSWE.loc[opSWE['basinSWE_amsr']==-99,'basinSWE_amsr']=np.nan\n",
    "\n",
    "#calculate the cubic spline estimate of the AMSR data (same as lab 1)\n",
    "amsrSWE_interp=pd.DataFrame(data={'doy':opSWE['doy'],'basinSWE_amsr': opSWE['basinSWE_amsr'].interpolate(method='cubicspline')})\n",
    "\n",
    "# 7 day  moving average of the interpolated data\n",
    "amsrSWE_avg=amsrSWE_interp.rolling(7).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define plot space\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "\n",
    "#define x and y axis data - ERA 5 SWE forecast - POINTS\n",
    "#opSWE.plot.scatter( x='doy',y='basinSWE_amsr',\n",
    "#                                        color='green', label= 'AMSR SWE Estimate', ax=ax)\n",
    "\n",
    "#define x and y axis data - ERA 5 SWE forecast - INTERPOLATION\n",
    "#amsrSWE_interp.plot(kind='line', x='doy',y='basinSWE_amsr',\n",
    "#                                        color='green', label= 'AMSR SWE Estimate', ax=ax)\n",
    "\n",
    "\n",
    "#define x and y axis data - ERA 5 SWE forecast - rolling average\n",
    "amsrSWE_avg.plot(kind='line', x='doy',y='basinSWE_amsr', style='--',\n",
    "                                        color='green', label= 'AMSR SWE Estimate', ax=ax)\n",
    "\n",
    "\n",
    "#define x and y axis data - AMSR-Unified SWE estimate\n",
    "opSWE.plot(kind='line',x='doy',y='basinSWE_era5',color='black', label= 'ERA 5 SWE forecast', ax=ax)\n",
    "\n",
    "\n",
    "#define x and y axis data - Machine Learning Prediction\n",
    "SWE.groupby('doy')['pxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='orange', label= 'Machine Learning Prediciton', ax=ax)\n",
    "\n",
    "#define x and y axis data - Truth data from SWE reconstruciton\n",
    "SWE.groupby('doy')['truthSWEpxlVol'].sum().plot(kind='line',\n",
    "                                        x='day of year',y='SWE (mm)',\n",
    "                                        color='purple', label = 'SWE reconstruction', ax=ax)\n",
    "\n",
    "#set plot title and axes labels\n",
    "ax.set(title=str(newTestYear)+' SWE prediciton each day',\n",
    "       xlabel='day of year',\n",
    "       ylabel='SWE (Km3)')\n",
    "\n",
    "#plot all the data\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
